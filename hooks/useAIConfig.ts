"use client"

import { useState, useEffect } from "react"

interface AIConfig {
  model: string
  temperature: number
  maxTokens: number
  systemPrompt: string
  followupPrompt: string
  analysisPrompt: string
  isConfigured: boolean
}

const defaultConfig: AIConfig = {
  model: "gpt-4o-mini",
  temperature: 0.7,
  maxTokens: 1000,
  systemPrompt:
    "Voc√™ √© um assistente especializado em vendas e follow-up de or√ßamentos. Seja profissional, objetivo e √∫til.",
  followupPrompt: `Analise este or√ßamento e forne√ßa sugest√µes espec√≠ficas para o pr√≥ximo follow-up em formato de lista clara:

‚Ä¢ **Pr√≥xima A√ß√£o:** [Qual a melhor abordagem para este cliente?]
‚Ä¢ **Timing:** [Quando fazer o pr√≥ximo contato?]
‚Ä¢ **Argumentos:** [Que argumentos usar?]
‚Ä¢ **Obje√ß√µes:** [Como superar poss√≠veis obje√ß√µes?]
‚Ä¢ **Estrat√©gia:** [Estrat√©gia espec√≠fica para este caso]

Use SEMPRE este formato de lista com bullets (‚Ä¢) e negrito (**) nos t√≠tulos.
Seja direto e pr√°tico. M√°ximo 5 pontos.`,
  analysisPrompt:
    "Analise este or√ßamento e forne√ßa: 1) Probabilidade de fechamento (0-100%), 2) Motivos que influenciam positivamente, 3) Estrat√©gias recomendadas, 4) Pr√≥ximos passos sugeridos.",
  isConfigured: false,
}

export function useAIConfig() {
  const [config, setConfig] = useState<AIConfig>(defaultConfig)
  const [isLoading, setIsLoading] = useState(false)

  useEffect(() => {
    // Carregar configura√ß√£o do localStorage (sem API Key)
    const savedConfig = localStorage.getItem("ai-config")
    if (savedConfig) {
      try {
        const parsed = JSON.parse(savedConfig)
        // Remover apiKey se existir (migra√ß√£o)
        delete parsed.apiKey
        const mergedConfig = { ...defaultConfig, ...parsed, isConfigured: true }
        setConfig(mergedConfig)
        console.log("‚úÖ Configura√ß√£o da IA carregada do localStorage:", {
          model: mergedConfig.model,
          temperature: mergedConfig.temperature,
        })
      } catch (error) {
        console.error("‚ùå Erro ao carregar configura√ß√£o da IA:", error)
      }
    }
  }, [])

  const updateConfig = (newConfig: AIConfig) => {
    const configWithFlag = {
      ...newConfig,
      isConfigured: true,
    }
    setConfig(configWithFlag)
    // Salvar sem API Key (apenas configura√ß√µes do modelo)
    const configToSave = { ...configWithFlag }
    delete (configToSave as any).apiKey
    localStorage.setItem("ai-config", JSON.stringify(configToSave))
    console.log("‚úÖ Configura√ß√£o da IA atualizada:", {
      model: configWithFlag.model,
      isConfigured: configWithFlag.isConfigured,
    })
  }

  const testConnection = async (): Promise<{ success: boolean; message: string }> => {
    setIsLoading(true)
    try {
      console.log("üß™ Testando conex√£o com IA usando API Key do servidor...")

      const response = await fetch("/api/ai-chat", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({
          message: "Teste de conex√£o - responda apenas 'Conex√£o OK'",
          budget: null,
          config: {
            model: config.model,
            temperature: config.temperature,
            maxTokens: 100,
            systemPrompt: "Voc√™ √© um assistente de teste. Responda apenas 'Conex√£o OK'.",
          },
        }),
      })

      if (response.ok) {
        const data = await response.json()
        console.log("‚úÖ Teste de conex√£o bem-sucedido:", data)
        return { success: true, message: "‚úÖ Conex√£o com OpenAI estabelecida com sucesso!" }
      } else {
        const errorData = await response.json()
        console.error("‚ùå Erro no teste de conex√£o:", errorData)
        return { success: false, message: `‚ùå Erro: ${errorData.error || "Falha na conex√£o"}` }
      }
    } catch (error: any) {
      console.error("‚ùå Erro de rede no teste:", error)
      return { success: false, message: `‚ùå Erro de rede: ${error.message}` }
    } finally {
      setIsLoading(false)
    }
  }

  return {
    config,
    updateConfig,
    testConnection,
    isLoading,
  }
}
